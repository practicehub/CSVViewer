import initSqlJs, { Database } from 'sql.js';
import path from 'path';
import fs from 'fs';

// æ•°æ®åº“ç±»å‹æšä¸¾
export enum DbType {
  SQLITE = 'sqlite',    // SQL.js (å†…å­˜æ•°æ®åº“ï¼Œé€‚åˆå°æ–‡ä»¶)
  FILEDB = 'filedb'     // æ–‡ä»¶æ•°æ®åº“ (é€‚åˆå¤§æ–‡ä»¶)
}

// æ•°æ®åº“æ¥å£
export interface IDatabase {
  init(): Promise<void>;
  run(sql: string, params?: any[]): any;
  get(sql: string, params?: any[]): any;
  all(sql: string, params?: any[]): any[];
  save(): void;
  close(): void;
}

// SQL.jsæ•°æ®åº“å®ç° (é€‚åˆå°æ–‡ä»¶)
export class SqliteDatabase implements IDatabase {
  private db: Database | null = null;
  private dbPath: string;

  constructor(dbPath: string) {
    this.dbPath = dbPath;
  }

  async init(): Promise<void> {
    const SQL = await initSqlJs();
    
    if (fs.existsSync(this.dbPath)) {
      const buffer = fs.readFileSync(this.dbPath);
      this.db = new SQL.Database(buffer);
    } else {
      this.db = new SQL.Database();
    }

    // åˆ›å»ºè¡¨ç»“æ„
    this.createTables();
  }

  private createTables(): void {
    if (!this.db) throw new Error('Database not initialized');
    
    this.db.run(`
      CREATE TABLE IF NOT EXISTS users (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        username TEXT NOT NULL UNIQUE,
        password TEXT NOT NULL,
        is_admin INTEGER DEFAULT 0,
        created_at DATETIME DEFAULT CURRENT_TIMESTAMP
      )
    `);

    this.db.run(`
      CREATE TABLE IF NOT EXISTS csv_files (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        user_id INTEGER NOT NULL,
        filename TEXT NOT NULL,
        original_name TEXT NOT NULL,
        row_count INTEGER DEFAULT 0,
        upload_date DATETIME DEFAULT CURRENT_TIMESTAMP,
        FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE
      )
    `);

    this.db.run(`
      CREATE TABLE IF NOT EXISTS csv_data (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        file_id INTEGER NOT NULL,
        row_number INTEGER NOT NULL,
        row_data TEXT NOT NULL,
        is_header INTEGER DEFAULT 0,
        FOREIGN KEY (file_id) REFERENCES csv_files(id) ON DELETE CASCADE
      )
    `);

    // åˆ›å»ºç´¢å¼•
    this.db.run(`CREATE INDEX IF NOT EXISTS idx_csv_data_file_id ON csv_data(file_id)`);
    this.db.run(`CREATE INDEX IF NOT EXISTS idx_csv_data_row_number ON csv_data(file_id, row_number)`);
    this.db.run(`CREATE INDEX IF NOT EXISTS idx_csv_data_header ON csv_data(file_id, is_header)`);
  }

  run(sql: string, params: any[] = []): any {
    if (!this.db) throw new Error('Database not initialized');
    const result = this.db.run(sql, params);
    this.save();
    return result;
  }

  get(sql: string, params: any[] = []): any {
    if (!this.db) throw new Error('Database not initialized');
    const stmt = this.db.prepare(sql);
    stmt.bind(params);
    const result = stmt.step() ? stmt.getAsObject() : null;
    stmt.free();
    return result;
  }

  all(sql: string, params: any[] = []): any[] {
    if (!this.db) throw new Error('Database not initialized');
    const stmt = this.db.prepare(sql);
    stmt.bind(params);
    const results: any[] = [];
    while (stmt.step()) {
      results.push(stmt.getAsObject());
    }
    stmt.free();
    return results;
  }

  save(): void {
    if (!this.db) return;
    const data = this.db.export();
    const chunkSize = 100 * 1024 * 1024; // 100MB chunks
    for (let i = 0; i < data.length; i += chunkSize) {
      const chunk = data.slice(i, i + chunkSize);
      const flag = i === 0 ? 'w' : 'a';
      fs.writeFileSync(this.dbPath, chunk, { flag });
    }
  }

  close(): void {
    if (this.db) {
      this.db.close();
      this.db = null;
    }
  }
}

// æ–‡ä»¶æ•°æ®åº“å®ç° (é€‚åˆå¤§æ–‡ä»¶ï¼ŒåŸºäºæ–‡ä»¶ç³»ç»Ÿ)
export class FileDatabase implements IDatabase {
  private dataDir: string;
  private users: Map<string, any> = new Map();
  private csvFiles: Map<number, any> = new Map();
  private csvData: Map<number, Map<number, any>> = new Map();
  private pendingWrites: Map<number, any[]> = new Map(); // æ‰¹é‡å†™å…¥ç¼“å†²åŒº
  private writeTimer: NodeJS.Timeout | null = null;
  private maxMemoryRows = 10000000; // é™åˆ¶å†…å­˜ä¸­ä¿å­˜çš„è¡Œæ•° (è°ƒæ•´ä¸º1000ä¸‡è¡Œï¼Œå……åˆ†åˆ©ç”¨32GB RAM)

  constructor(dataDir: string) {
    this.dataDir = dataDir;
    this.ensureDataDir();
  }

  private ensureDataDir(): void {
    if (!fs.existsSync(this.dataDir)) {
      fs.mkdirSync(this.dataDir, { recursive: true });
    }
  }

  async init(): Promise<void> {
    // ä»æ–‡ä»¶åŠ è½½æ•°æ®
    this.loadUsers();
    this.loadCsvFiles();
    console.log('File database initialized for large file processing');
  }

  // ä»æ–‡ä»¶åŠ è½½CSVæ•°æ®ï¼ˆæŒ‰éœ€åŠ è½½ï¼Œæ”¯æŒå¤§æ–‡ä»¶ï¼‰
  private loadCsvDataFromFile(fileId: number): void {
    const dataFile = path.join(this.dataDir, `csv_data_${fileId}.jsonl`);
    if (!fs.existsSync(dataFile)) return;

    try {
      const fileData = new Map<number, any>();
      const maxLoadRows = 100; // å‡å°‘åŠ è½½è¡Œæ•°ï¼Œæé«˜å“åº”é€Ÿåº¦
      
      // æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼Œå†³å®šä½¿ç”¨åŒæ­¥è¿˜æ˜¯å¼‚æ­¥è¯»å–
      const stats = fs.statSync(dataFile);
      const fileSizeMB = stats.size / (1024 * 1024);
      
      if (fileSizeMB < 100) { // å°äº100MBçš„æ–‡ä»¶ä½¿ç”¨åŒæ­¥è¯»å–
        const maxReadBytes = 50 * 1024; // æœ€å¤šè¯»å–50KB
        const fileBuffer = fs.readFileSync(dataFile);
        const buffer = fileBuffer.toString('utf-8', 0, Math.min(maxReadBytes, fileBuffer.length));
        const lines = buffer.split('\n');
        
        let lineCount = 0;
        for (const line of lines) {
          if (line.trim() && lineCount < maxLoadRows) {
            try {
              const row = JSON.parse(line);
              fileData.set(row.row_number, row);
              lineCount++;
            } catch (e) {
              console.warn(`Failed to parse line in file ${fileId}:`, line.substring(0, 100));
            }
          }
        }
        
        this.csvData.set(fileId, fileData);
        console.log(`ğŸ“‚ ä»æ–‡ä»¶åŒæ­¥åŠ è½½äº† ${fileData.size} è¡Œæ•°æ® (æ–‡ä»¶ID: ${fileId})`);
        
        // å¼‚æ­¥åŠ è½½æ›´å¤šæ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
        this.loadMoreDataAsync(fileId, maxLoadRows);
      } else { // å¤§æ–‡ä»¶ä½¿ç”¨çº¯æµå¼è¯»å–
        console.log(`ğŸŒŠ æ£€æµ‹åˆ°å¤§æ–‡ä»¶ (${fileSizeMB.toFixed(1)}MB)ï¼Œä½¿ç”¨æµå¼è¯»å– (æ–‡ä»¶ID: ${fileId})`);
        this.loadLargeFileStreaming(fileId, maxLoadRows);
      }
      
    } catch (error) {
      console.error(`Failed to load CSV data for file ${fileId}:`, error);
    }
  }

  // æµå¼åŠ è½½å¤§æ–‡ä»¶
  private loadLargeFileStreaming(fileId: number, maxLoadRows: number): void {
    const dataFile = path.join(this.dataDir, `csv_data_${fileId}.jsonl`);
    const fileData = new Map<number, any>();
    
    try {
      const readStream = fs.createReadStream(dataFile, { 
        encoding: 'utf-8', 
        start: 0,
        highWaterMark: 64 * 1024 // 64KB chunks
      });
      
      let buffer = '';
      let lineCount = 0;
      let headerFound = false;
      
      readStream.on('data', (chunk: string | Buffer) => {
        const chunkStr = chunk instanceof Buffer ? chunk.toString('utf-8') : chunk;
        buffer += chunkStr;
        const lines = buffer.split('\n');
        buffer = lines.pop() || '';
        
        for (const line of lines) {
          if (line.trim()) {
            try {
              const row = JSON.parse(line);
              
              // ä¼˜å…ˆåŠ è½½è¡¨å¤´ï¼ˆrow_number === 0ï¼‰
              if (row.row_number === 0 && !headerFound) {
                fileData.set(row.row_number, row);
                headerFound = true;
                console.log(`[DEBUG] æ‰¾åˆ°è¡¨å¤´è¡Œ: ${row.row_number}`);
              } else if (lineCount < maxLoadRows) {
                fileData.set(row.row_number, row);
                lineCount++;
              }
            } catch (e) {
              console.warn(`Failed to parse line in file ${fileId}:`, line.substring(0, 100));
            }
          }
        }
        
        // å¦‚æœå·²ç»åŠ è½½äº†è¶³å¤Ÿçš„è¡Œæ•°ä¸”æ‰¾åˆ°äº†è¡¨å¤´ï¼Œåœæ­¢è¯»å–
        if (lineCount >= maxLoadRows && headerFound) {
          readStream.destroy();
        }
      });
      
      readStream.on('end', () => {
        // å¤„ç†æœ€åçš„buffer
        if (buffer.trim()) {
          try {
            const row = JSON.parse(buffer);
            
            // ä¼˜å…ˆåŠ è½½è¡¨å¤´
            if (row.row_number === 0 && !headerFound) {
              fileData.set(row.row_number, row);
              headerFound = true;
              console.log(`[DEBUG] åœ¨æœ€åbufferä¸­æ‰¾åˆ°è¡¨å¤´è¡Œ: ${row.row_number}`);
            } else if (lineCount < maxLoadRows) {
              fileData.set(row.row_number, row);
              lineCount++;
            }
          } catch (e) {
            console.warn(`Failed to parse final line in file ${fileId}:`, buffer.substring(0, 100));
          }
        }
        
        this.csvData.set(fileId, fileData);
        console.log(`ğŸ“‚ æµå¼åŠ è½½äº† ${fileData.size} è¡Œæ•°æ® (æ–‡ä»¶ID: ${fileId}, è¡¨å¤´: ${headerFound})`);
        
        // ç»§ç»­å¼‚æ­¥åŠ è½½æ›´å¤šæ•°æ®
        this.loadMoreDataAsync(fileId, maxLoadRows);
      });
      
      readStream.on('error', (error) => {
        console.error(`Stream error reading file ${fileId}:`, error);
      });
      
    } catch (error) {
      console.error(`Failed to stream large file ${fileId}:`, error);
    }
  }

  // å¼‚æ­¥åŠ è½½æ›´å¤šæ•°æ®
  private loadMoreDataAsync(fileId: number, startRow: number): void {
    const dataFile = path.join(this.dataDir, `csv_data_${fileId}.jsonl`);
    if (!fs.existsSync(dataFile)) return;

    try {
      const fileData = this.csvData.get(fileId);
      if (!fileData) return;

      const readStream = fs.createReadStream(dataFile, { encoding: 'utf-8', start: 0 });
      let buffer = '';
      let lineCount = 0;
      const maxLoadRows = 1000; // å¼‚æ­¥åŠ è½½æ›´å¤šè¡Œ
      
      readStream.on('data', (chunk: string | Buffer) => {
        const chunkStr = chunk instanceof Buffer ? chunk.toString('utf-8') : chunk;
        buffer += chunkStr;
        const lines = buffer.split('\n');
        buffer = lines.pop() || '';
        
        for (const line of lines) {
          if (line.trim() && lineCount < maxLoadRows) {
            try {
              const row = JSON.parse(line);
              if (!fileData.has(row.row_number)) {
                fileData.set(row.row_number, row);
                lineCount++;
              }
            } catch (e) {
              // å¿½ç•¥è§£æé”™è¯¯
            }
          }
        }
        
        if (lineCount >= maxLoadRows) {
          readStream.destroy();
        }
      });
      
      readStream.on('end', () => {
        if (buffer.trim()) {
          try {
            const row = JSON.parse(buffer);
            if (!fileData.has(row.row_number)) {
              fileData.set(row.row_number, row);
            }
          } catch (e) {
            // å¿½ç•¥è§£æé”™è¯¯
          }
        }
        console.log(`ğŸ“‚ å¼‚æ­¥åŠ è½½å®Œæˆï¼Œæ€»å…± ${fileData.size} è¡Œæ•°æ® (æ–‡ä»¶ID: ${fileId})`);
      });
      
    } catch (error) {
      console.error(`Failed to async load more data for file ${fileId}:`, error);
    }
  }

  // åŒæ­¥æŸ¥æ‰¾ç‰¹å®šè¡Œå·çš„æ•°æ®ï¼ˆç”¨äºå¤§æ–‡ä»¶ï¼‰
  private findRowInFile(fileId: number, rowNumber: number): Promise<any> {
    const dataFile = path.join(this.dataDir, `csv_data_${fileId}.jsonl`);
    if (!fs.existsSync(dataFile)) return Promise.resolve(null);

    try {
      const readStream = fs.createReadStream(dataFile, { encoding: 'utf-8' });
      let buffer = '';
      let found = false;
      let result: any = null;
      
      return new Promise<any>((resolve) => {
        readStream.on('data', (chunk: string | Buffer) => {
          const chunkStr = chunk instanceof Buffer ? chunk.toString('utf-8') : chunk;
          buffer += chunkStr;
          const lines = buffer.split('\n');
          buffer = lines.pop() || ''; // ä¿ç•™æœ€åä¸€ä¸ªä¸å®Œæ•´çš„è¡Œ
          
          for (const line of lines) {
            if (line.trim()) {
              try {
                const row = JSON.parse(line);
                if (row.row_number === rowNumber) {
                  result = row;
                  found = true;
                  readStream.destroy();
                  break;
                }
              } catch (e) {
                // å¿½ç•¥è§£æé”™è¯¯çš„è¡Œ
              }
            }
          }
        });
        
        readStream.on('end', () => {
          // å¤„ç†æœ€åçš„buffer
          if (!found && buffer.trim()) {
            try {
              const row = JSON.parse(buffer);
              if (row.row_number === rowNumber) {
                result = row;
              }
            } catch (e) {
              // å¿½ç•¥è§£æé”™è¯¯
            }
          }
          resolve(result);
        });
        
        readStream.on('error', () => {
          resolve(null);
        });
      });
    } catch (error) {
      console.error(`Failed to find row ${rowNumber} in file ${fileId}:`, error);
      return Promise.resolve(null);
    }
  }

  private loadUsers(): void {
    const usersFile = path.join(this.dataDir, 'users.json');
    if (fs.existsSync(usersFile)) {
      const data = fs.readFileSync(usersFile, 'utf-8');
      const users = JSON.parse(data);
      this.users = new Map(users.map((u: any) => [u.username, u]));
    }
  }

  private loadCsvFiles(): void {
    const filesFile = path.join(this.dataDir, 'csv_files.json');
    if (fs.existsSync(filesFile)) {
      const data = fs.readFileSync(filesFile, 'utf-8');
      this.csvFiles = new Map(JSON.parse(data).map((f: any) => [f.id, f]));
    }
  }

  private saveUsers(): void {
    const usersFile = path.join(this.dataDir, 'users.json');
    const users = Array.from(this.users.values());
    fs.writeFileSync(usersFile, JSON.stringify(users, null, 2));
  }

  private saveCsvFiles(): void {
    const filesFile = path.join(this.dataDir, 'csv_files.json');
    const files = Array.from(this.csvFiles.values());
    fs.writeFileSync(filesFile, JSON.stringify(files, null, 2));
  }

  // æ‰¹é‡å†™å…¥CSVæ•°æ®åˆ°æ–‡ä»¶
  private flushCsvData(fileId: number): void {
    const pending = this.pendingWrites.get(fileId);
    if (!pending || pending.length === 0) return;

    const dataFile = path.join(this.dataDir, `csv_data_${fileId}.jsonl`); // ä½¿ç”¨JSONLæ ¼å¼
    
    // åˆ†æ‰¹å†™å…¥ï¼Œé¿å…å­—ç¬¦ä¸²é•¿åº¦é™åˆ¶
    const batchSize = 1000;
    for (let i = 0; i < pending.length; i += batchSize) {
      const batch = pending.slice(i, i + batchSize);
      const lines = batch.map(row => JSON.stringify(row)).join('\n') + '\n';
      fs.appendFileSync(dataFile, lines);
    }
    
    // æ¸…ç©ºç¼“å†²åŒº
    this.pendingWrites.delete(fileId);
  }

  // å®šæœŸæ‰¹é‡å†™å…¥
  private scheduleFlush(fileId: number): void {
    if (this.writeTimer) return;
    
    this.writeTimer = setTimeout(() => {
      for (const [fid] of this.pendingWrites) {
        this.flushCsvData(fid);
      }
      this.writeTimer = null;
    }, 3000); // 3ç§’æ‰¹é‡å†™å…¥ä¸€æ¬¡
  }

  run(sql: string, params: any[] = []): any {
    // ç®€åŒ–çš„SQLè§£æï¼Œä¸»è¦å¤„ç†INSERTæ“ä½œ
    if (sql.includes('INSERT INTO users')) {
      const [_, username, password] = params;
      const user = {
        id: this.users.size + 1,
        username,
        password,
        created_at: new Date().toISOString()
      };
      this.users.set(username, user);
      this.saveUsers();
      return { lastInsertRowid: user.id };
    }

    if (sql.includes('INSERT INTO csv_files')) {
      const [userId, filename, originalName] = params;
      const file = {
        id: this.csvFiles.size + 1,
        user_id: userId,
        filename,
        original_name: originalName,
        row_count: 0,
        upload_date: new Date().toISOString()
      };
      this.csvFiles.set(file.id, file);
      this.csvData.set(file.id, new Map());
      this.saveCsvFiles();
      return { lastInsertRowid: file.id };
    }

    if (sql.includes('INSERT INTO csv_data')) {
      const [fileId, rowNumber, rowData, isHeader] = params;
      const fileData = this.csvData.get(fileId);
      if (fileData) {
        const row = {
          file_id: fileId,
          row_number: rowNumber,
          row_data: rowData,
          is_header: isHeader
        };
        
        // é™åˆ¶å†…å­˜ä¸­çš„è¡Œæ•°ï¼Œé¿å…Mapå¤§å°é™åˆ¶
        if (fileData.size < this.maxMemoryRows) {
          fileData.set(rowNumber, row);
        } else if (fileData.size === this.maxMemoryRows) {
          // è¾¾åˆ°é™åˆ¶æ—¶æ¸…ç†å†…å­˜ï¼Œåªä¿ç•™æœ€è¿‘çš„æ•°æ®
          console.log(`âš ï¸  å†…å­˜é™åˆ¶è¾¾åˆ°ï¼Œæ¸…ç†æ–‡ä»¶ ${fileId} çš„å†…å­˜æ•°æ®`);
          fileData.clear();
        }
        
        // æ·»åŠ åˆ°æ‰¹é‡å†™å…¥ç¼“å†²åŒº
        if (!this.pendingWrites.has(fileId)) {
          this.pendingWrites.set(fileId, []);
        }
        this.pendingWrites.get(fileId)!.push(row);
        
        // å®šæœŸæ‰¹é‡å†™å…¥
        this.scheduleFlush(fileId);
      }
      return {};
    }

    if (sql.includes('UPDATE csv_files SET row_count')) {
      const [rowCount, fileId] = params;
      const file = this.csvFiles.get(fileId);
      if (file) {
        file.row_count = rowCount;
        this.saveCsvFiles();
      }
      return {};
    }

    if (sql.includes('DELETE FROM csv_data')) {
      const [fileId] = params;
      // åˆ é™¤å†…å­˜ä¸­çš„æ•°æ®
      this.csvData.delete(fileId);
      // åˆ é™¤å¾…å†™å…¥ç¼“å†²åŒº
      this.pendingWrites.delete(fileId);
      // åˆ é™¤æ•°æ®æ–‡ä»¶
      const dataFile = path.join(this.dataDir, `csv_data_${fileId}.jsonl`);
      if (fs.existsSync(dataFile)) {
        fs.unlinkSync(dataFile);
        console.log(`[DELETE] åˆ é™¤æ•°æ®æ–‡ä»¶: csv_data_${fileId}.jsonl`);
      }
      return {};
    }

    if (sql.includes('DELETE FROM csv_files')) {
      const [fileId] = params;
      this.csvFiles.delete(fileId);
      this.csvData.delete(fileId);
      this.pendingWrites.delete(fileId);
      this.saveCsvFiles();
      return {};
    }

    return {};
  }

  async getAsync(sql: string, params: any[] = []): Promise<any> {
    if (sql.includes('SELECT') && sql.includes('users')) {
      const [username] = params;
      return this.users.get(username) || null;
    }

    if (sql.includes('SELECT') && sql.includes('csv_files')) {
      if (sql.includes('filename')) {
        const [filename] = params;
        return Array.from(this.csvFiles.values()).find(file => file.filename === filename) || null;
      } else {
        const [fileId] = params;
        return this.csvFiles.get(fileId) || null;
      }
    }

    if (sql.includes('SELECT') && sql.includes('csv_data')) {
      const [fileId, rowNumber] = params;
      let fileData = this.csvData.get(fileId);
      
      // å¦‚æœæ•°æ®ä¸åœ¨å†…å­˜ä¸­ï¼Œä»æ–‡ä»¶åŠ è½½
      if (!fileData) {
        this.loadCsvDataFromFile(fileId);
        // å‡å°‘ç­‰å¾…æ—¶é—´ï¼Œæé«˜å“åº”é€Ÿåº¦
        await this.waitForDataLoad(fileId);
        fileData = this.csvData.get(fileId);
      }
      
      if (fileData) {
        if (rowNumber !== undefined) {
          // æŸ¥æ‰¾ç‰¹å®šè¡Œå·
          const row = fileData.get(rowNumber);
          if (row) {
            return row;
          }
          // å¦‚æœå†…å­˜ä¸­æ²¡æœ‰ï¼Œä»æ–‡ä»¶æŸ¥æ‰¾
          return await this.findRowInFile(fileId, rowNumber);
        } else {
          // æŸ¥æ‰¾è¡¨å¤´ - ä¼˜åŒ–ç­‰å¾…æ—¶é—´
          let attempts = 0;
          let headerRow = Array.from(fileData.values())
            .find(row => row.file_id === fileId && row.is_header === 1);
          
          // å‡å°‘ç­‰å¾…æ¬¡æ•°å’Œé—´éš”ï¼Œæé«˜å“åº”é€Ÿåº¦
          while (!headerRow && attempts < 3) {
            await new Promise(resolve => setTimeout(resolve, 100));
            headerRow = Array.from(fileData.values())
              .find(row => row.file_id === fileId && row.is_header === 1);
            attempts++;
          }
          
          return headerRow || null;
        }
      }
    }

    if (sql.includes('COUNT')) {
      const [fileId] = params;
      let fileData = this.csvData.get(fileId);
      
      // å¦‚æœæ•°æ®ä¸åœ¨å†…å­˜ä¸­ï¼Œä»æ–‡ä»¶åŠ è½½
      if (!fileData) {
        this.loadCsvDataFromFile(fileId);
        // å‡å°‘ç­‰å¾…æ—¶é—´
        await this.waitForDataLoad(fileId);
        fileData = this.csvData.get(fileId);
      }
      
      if (fileData) {
        const filteredRows = Array.from(fileData.values())
          .filter(row => row.file_id === fileId && row.is_header === 0);
        return { total: filteredRows.length };
      }
    }

    return null;
  }

  // ç­‰å¾…æ•°æ®åŠ è½½å®Œæˆ - ä¼˜åŒ–æ€§èƒ½
  private async waitForDataLoad(fileId: number): Promise<void> {
    let attempts = 0;
    while (!this.csvData.has(fileId) && attempts < 5) {
      await new Promise(resolve => setTimeout(resolve, 50));
      attempts++;
    }
  }

  get(sql: string, params: any[] = []): any {
    if (sql.includes('SELECT') && sql.includes('users')) {
      const [username] = params;
      return this.users.get(username) || null;
    }

    if (sql.includes('SELECT') && sql.includes('csv_files')) {
      if (sql.includes('filename')) {
        const [filename] = params;
        return Array.from(this.csvFiles.values()).find(file => file.filename === filename) || null;
      } else {
        const [fileId] = params;
        return this.csvFiles.get(fileId) || null;
      }
    }

    if (sql.includes('SELECT') && sql.includes('csv_data')) {
      const [fileId, rowNumber] = params;
      let fileData = this.csvData.get(fileId);
      
      // å¦‚æœæ•°æ®ä¸åœ¨å†…å­˜ä¸­ï¼Œä»æ–‡ä»¶åŠ è½½
      if (!fileData) {
        this.loadCsvDataFromFile(fileId);
        fileData = this.csvData.get(fileId);
      }
      
      if (fileData && rowNumber !== undefined) {
        return fileData.get(rowNumber) || null;
      }
    }

    if (sql.includes('COUNT')) {
      const [fileId] = params;
      let fileData = this.csvData.get(fileId);
      
      // å¦‚æœæ•°æ®ä¸åœ¨å†…å­˜ä¸­ï¼Œä»æ–‡ä»¶åŠ è½½
      if (!fileData) {
        this.loadCsvDataFromFile(fileId);
        fileData = this.csvData.get(fileId);
      }
      
      if (fileData) {
        const filteredRows = Array.from(fileData.values())
          .filter(row => row.file_id === fileId && row.is_header === 0);
        return { total: filteredRows.length };
      }
    }

    return null;
  }

  all(sql: string, params: any[] = []): any[] {
    if (sql.includes('SELECT') && sql.includes('csv_files')) {
      const [userId] = params;
      return Array.from(this.csvFiles.values())
        .filter(file => file.user_id === userId)
        .sort((a, b) => new Date(b.upload_date).getTime() - new Date(a.upload_date).getTime());
    }

    if (sql.includes('SELECT') && sql.includes('csv_data')) {
      // è§£æSQLæŸ¥è¯¢å‚æ•°
      const [fileId, limit, offset] = params;
      let fileData = this.csvData.get(fileId);
      
      // å¦‚æœæ•°æ®ä¸åœ¨å†…å­˜ä¸­ï¼Œä»æ–‡ä»¶åŠ è½½
      if (!fileData) {
        this.loadCsvDataFromFile(fileId);
        fileData = this.csvData.get(fileId);
      }
      
      if (fileData) {
        let rows = Array.from(fileData.values())
          .filter(row => row.file_id === fileId && row.is_header === 0)
          .sort((a, b) => a.row_number - b.row_number);
        
        // åº”ç”¨LIMITå’ŒOFFSET
        if (offset !== undefined && limit !== undefined) {
          rows = rows.slice(offset, offset + limit);
        } else if (limit !== undefined) {
          rows = rows.slice(0, limit);
        }
        
        return rows;
      }
    }

    if (sql.includes('COUNT')) {
      const [fileId] = params;
      let fileData = this.csvData.get(fileId);
      
      // å¦‚æœæ•°æ®ä¸åœ¨å†…å­˜ä¸­ï¼Œä»æ–‡ä»¶åŠ è½½
      if (!fileData) {
        this.loadCsvDataFromFile(fileId);
        fileData = this.csvData.get(fileId);
      }
      
      if (fileData) {
        const filteredRows = Array.from(fileData.values())
          .filter(row => row.file_id === fileId && row.is_header === 0);
        return [{ total: filteredRows.length }];
      }
    }

    return [];
  }

  save(): void {
    // å¼ºåˆ¶åˆ·æ–°æ‰€æœ‰å¾…å†™å…¥æ•°æ®
    for (const [fileId] of this.pendingWrites) {
      this.flushCsvData(fileId);
    }
  }

  close(): void {
    // ä¿å­˜æ‰€æœ‰å¾…å†™å…¥æ•°æ®
    this.save();
    
    // æ¸…ç†å†…å­˜
    this.users.clear();
    this.csvFiles.clear();
    this.csvData.clear();
    this.pendingWrites.clear();
    
    if (this.writeTimer) {
      clearTimeout(this.writeTimer);
      this.writeTimer = null;
    }
  }
}

// å•ä¾‹æ•°æ®åº“ç®¡ç†å™¨
class DatabaseManagerSingleton {
  private static instances: Map<DbType, DatabaseManager> = new Map();

  static async getInstance(dbType: DbType = DbType.SQLITE): Promise<DatabaseManager> {
    if (!this.instances.has(dbType)) {
      const dbManager = new DatabaseManager(dbType);
      await dbManager.init();
      this.instances.set(dbType, dbManager);
    }
    return this.instances.get(dbType)!;
  }

  static closeAll(): void {
    for (const dbManager of this.instances.values()) {
      dbManager.close();
    }
    this.instances.clear();
  }
}

// æ•°æ®åº“ç®¡ç†å™¨
export class DatabaseManager {
  private db: IDatabase;
  private dbType: DbType;

  constructor(dbType: DbType = DbType.SQLITE) {
    this.dbType = dbType;
    const dataDir = path.join(__dirname, '..', 'data');
    
    if (dbType === DbType.SQLITE) {
      const dbPath = process.env.DATABASE_PATH || path.join(dataDir, 'db.sqlite');
      this.db = new SqliteDatabase(dbPath);
    } else {
      this.db = new FileDatabase(dataDir);
    }
  }

  async init(): Promise<void> {
    await this.db.init();
  }

  run(sql: string, params: any[] = []): any {
    return this.db.run(sql, params);
  }

  async getAsync(sql: string, params: any[] = []): Promise<any> {
    if ('getAsync' in this.db) {
      return await (this.db as any).getAsync(sql, params);
    } else {
      return this.db.get(sql, params);
    }
  }

  get(sql: string, params: any[] = []): any {
    return this.db.get(sql, params);
  }

  all(sql: string, params: any[] = []): any[] {
    return this.db.all(sql, params);
  }

  save(): void {
    this.db.save();
  }

  close(): void {
    this.db.close();
  }

  getDbType(): DbType {
    return this.dbType;
  }

  // é™æ€æ–¹æ³•è·å–å•ä¾‹å®ä¾‹
  static async getInstance(dbType: DbType = DbType.SQLITE): Promise<DatabaseManager> {
    return await DatabaseManagerSingleton.getInstance(dbType);
  }

  static closeAll(): void {
    DatabaseManagerSingleton.closeAll();
  }
}

// æ™ºèƒ½æ•°æ®åº“é€‰æ‹©å™¨
export class SmartDatabaseSelector {
  static selectDatabase(fileSizeMB: number): DbType {
    // æ ¹æ®æ–‡ä»¶å¤§å°æ™ºèƒ½é€‰æ‹©æ•°æ®åº“
    if (fileSizeMB <= 50) { // 50MBä»¥ä¸‹ä½¿ç”¨SQL.js
      return DbType.SQLITE;
    } else { // 50MBä»¥ä¸Šä½¿ç”¨æ–‡ä»¶æ•°æ®åº“
      return DbType.FILEDB;
    }
  }

  static async createOptimizedDatabase(fileSizeMB: number): Promise<DatabaseManager> {
    const dbType = this.selectDatabase(fileSizeMB);
    const dbManager = new DatabaseManager(dbType);
    await dbManager.init();
    
    console.log(`ğŸ—„ï¸  é€‰æ‹©æ•°æ®åº“ç±»å‹: ${dbType} (æ–‡ä»¶å¤§å°: ${fileSizeMB}MB)`);
    
    return dbManager;
  }
}

export default DatabaseManager;
