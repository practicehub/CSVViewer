import express, { Request, Response } from 'express';
import multer from 'multer';
import path from 'path';
import fs from 'fs';
import Papa from 'papaparse';
import { SmartDatabaseSelector, DatabaseManager, DbType } from '../db-manager';
import { authenticateToken, AuthRequest } from '../middleware/auth';

const router = express.Router();

// é…ç½®æ–‡ä»¶ä¸Šä¼ 
const uploadDir = path.join(__dirname, '../../uploads');
if (!fs.existsSync(uploadDir)) {
  fs.mkdirSync(uploadDir, { recursive: true });
}

const storage = multer.diskStorage({
  destination: (req, file, cb) => {
    cb(null, uploadDir);
  },
  filename: (req, file, cb) => {
    const timestamp = Date.now();
    const ext = path.extname(file.originalname);
    const basename = path.basename(file.originalname, ext);
    cb(null, `${basename}_${timestamp}${ext}`);
  }
});

const upload = multer({
  storage: storage,
  limits: { 
    fileSize: 12 * 1024 * 1024 * 1024, // 12GB limit for large log files
    fieldSize: 12 * 1024 * 1024 * 1024, // 12GB field size
    files: 1 // Only one file at a time
  },
  fileFilter: (req, file, cb) => {
    if (file.mimetype === 'text/csv' || path.extname(file.originalname).toLowerCase() === '.csv') {
      cb(null, true);
    } else {
      cb(new Error('Only CSV files are allowed'));
    }
  }
});

// æµå¼å¤„ç†CSVæ–‡ä»¶ä¸Šä¼  - ä¼˜åŒ–å¤§æ–‡ä»¶å¤„ç†
router.post('/upload', authenticateToken, upload.single('file'), async (req: AuthRequest, res: Response) => {
  const overallStartTime = Date.now();
  let fileUploadTime = 0;
  let parseTime = 0;
  let dbInsertTime = 0;
  let dbManager: DatabaseManager | null = null;
  
  try {
    if (!req.file) {
      return res.status(400).json({ message: 'No file uploaded' });
    }

    const userId = req.userId!;
    const filename = req.file.filename;
    const originalName = req.file.originalname;
    const filePath = path.join(uploadDir, filename);
    
    // è®°å½•æ–‡ä»¶ä¿¡æ¯
    const fileSizeMB = (req.file.size / (1024 * 1024)).toFixed(2);
    const fileSizeGB = (req.file.size / (1024 * 1024 * 1024)).toFixed(2);
    
    console.log(`[UPLOAD-START] ç”¨æˆ· ${userId} å¼€å§‹ä¸Šä¼ æ–‡ä»¶: ${originalName} (${fileSizeGB}GB)`);

    // è®°å½•æ–‡ä»¶ä¸Šä¼ å®Œæˆæ—¶é—´
    fileUploadTime = Date.now() - overallStartTime;
    console.log(`[UPLOAD-FILE] æ–‡ä»¶ä¸Šä¼ å®Œæˆï¼Œè€—æ—¶: ${(fileUploadTime / 1000).toFixed(2)}ç§’`);

    // æ™ºèƒ½é€‰æ‹©æ•°æ®åº“ç±»å‹
    dbManager = await SmartDatabaseSelector.createOptimizedDatabase(parseFloat(fileSizeMB));
    
    // ä¿å­˜æ–‡ä»¶ä¿¡æ¯åˆ°æ•°æ®åº“
    const insertResult = dbManager.run(
      'INSERT INTO csv_files (user_id, filename, original_name) VALUES (?, ?, ?)',
      [userId, filename, originalName]
    );
    
    // è·å–æ–°æ’å…¥çš„æ–‡ä»¶ID
    let fileId: number;
    if (insertResult && insertResult.lastInsertRowid) {
      fileId = insertResult.lastInsertRowid;
    } else {
      // å…¼å®¹ä¸åŒçš„æ•°æ®åº“å®ç°
      const file = dbManager.get('SELECT id FROM csv_files WHERE filename = ? ORDER BY id DESC LIMIT 1', [filename]) as any;
      if (!file) {
        throw new Error('Failed to create file record');
      }
      fileId = file.id;
    }
    
    console.log(`[DB-INFO] æ–‡ä»¶è®°å½•å·²åˆ›å»ºï¼ŒID: ${fileId}`);

    // ä½¿ç”¨é«˜æ€§èƒ½æ‰¹é‡æ’å…¥ç­–ç•¥
    console.log(`[PARSE-START] å¼€å§‹æµå¼è§£æCSVæ–‡ä»¶...`);
    const parseStartTime = Date.now();
    
    let headers: string[] = [];
    let rowCount = 0;
    let saveCount = 0;
    const batchSize = 100000; // å¤§å¹…å¢åŠ æ‰¹æ¬¡å¤§å°ä»¥æé«˜æ€§èƒ½
    
    const dbInsertStartTime = Date.now();
    
    const parseResult = await new Promise<void>((resolve, reject) => {
      const stream = fs.createReadStream(filePath, { encoding: 'utf-8' });
      let isFirstRow = true;
      let batch: any[] = [];
      
      Papa.parse(stream, {
        header: false,
        skipEmptyLines: true,
        step: (row: any) => {
          try {
            if (isFirstRow) {
              // å¤„ç†è¡¨å¤´
              headers = row.data;
              const headerLine = JSON.stringify(headers);
              dbManager!.run('INSERT INTO csv_data (file_id, row_number, row_data, is_header) VALUES (?, ?, ?, ?)', 
                [fileId, 0, headerLine, 1]);
              isFirstRow = false;
              console.log(`[PARSE-HEADER] è¡¨å¤´å·²ä¿å­˜: ${headers.join(', ')}`);
            } else {
              // å¤„ç†æ•°æ®è¡Œ - ç´¯ç§¯åˆ°æ‰¹æ¬¡ä¸­
              rowCount++;
              const rowLine = JSON.stringify(row.data);
              batch.push([fileId, rowCount, rowLine, 0]);
              
              // æ‰¹é‡æ’å…¥
              if (batch.length >= batchSize) {
                // ç›´æ¥æ‰¹é‡æ’å…¥ï¼ˆSQL.jsä¸æ”¯æŒäº‹åŠ¡ï¼‰
                for (const item of batch) {
                  dbManager!.run('INSERT INTO csv_data (file_id, row_number, row_data, is_header) VALUES (?, ?, ?, ?)', item);
                }
                saveCount++;
                
                const elapsed = ((Date.now() - dbInsertStartTime) / 1000).toFixed(2);
                const speed = (rowCount / parseFloat(elapsed)).toFixed(0);
                
                // åŸºäºå®é™…å¤„ç†è¿›åº¦å’Œæ–‡ä»¶å¤§å°è®¡ç®—æ›´å‡†ç¡®çš„è¿›åº¦ç™¾åˆ†æ¯”
                const fileSizeMBNum = parseFloat(fileSizeMB);
                const elapsedSeconds = parseFloat(elapsed);
                
                // è®¡ç®—å½“å‰å¤„ç†é€Ÿåº¦ï¼ˆè¡Œ/ç§’ï¼‰
                const currentSpeed = elapsedSeconds > 0 ? rowCount / elapsedSeconds : 0;
                
                // åŸºäºæ–‡ä»¶å¤§å°å’Œå½“å‰é€Ÿåº¦ä¼°ç®—æ€»å¤„ç†æ—¶é—´
                let estimatedTotalRows = 0;
                let progress = 0;
                
                if (currentSpeed > 0) {
                  // ä½¿ç”¨å®é™…å¤„ç†é€Ÿåº¦æ¥ä¼°ç®—æ€»è¡Œæ•°
                  // æ ¹æ®æ–‡ä»¶å¤§å°è°ƒæ•´é¢„æœŸçš„è¡Œå¯†åº¦
                  let rowsPerMB = 1000; // é»˜è®¤å€¼
                  
                  if (fileSizeMBNum <= 10) {
                    rowsPerMB = 500;   // å°æ–‡ä»¶é€šå¸¸è¡Œæ•°è¾ƒå°‘
                  } else if (fileSizeMBNum <= 100) {
                    rowsPerMB = 1000;  // ä¸­å°æ–‡ä»¶
                  } else if (fileSizeMBNum <= 1000) {
                    rowsPerMB = 5000;  // ä¸­ç­‰æ–‡ä»¶
                  } else if (fileSizeMBNum <= 5000) {
                    rowsPerMB = 8000;  // å¤§æ–‡ä»¶
                  } else {
                    rowsPerMB = 10000; // è¶…å¤§æ–‡ä»¶
                  }
                  
                  estimatedTotalRows = Math.max(rowCount, fileSizeMBNum * rowsPerMB);
                  
                  // åŸºäºå®é™…è¿›åº¦å’Œä¼°ç®—è®¡ç®—ç™¾åˆ†æ¯”
                  progress = Math.min(99.9, (rowCount / estimatedTotalRows) * 100);
                } else {
                  // å¦‚æœè¿˜æ²¡æœ‰é€Ÿåº¦æ•°æ®ï¼Œä½¿ç”¨åŸºäºæ—¶é—´çš„ç®€å•ä¼°ç®—
                  const timeBasedProgress = Math.min(50, (elapsedSeconds / 60) * 10); // æœ€å¤š50%ï¼ŒåŸºäºæ—¶é—´
                  progress = timeBasedProgress;
                }
                
                // ç¡®ä¿è¿›åº¦ä¸ä¼šå€’é€€
                progress = Math.max(progress, 0);
                
                // åªåœ¨æ¯10%è¿›åº¦æ—¶æŠ¥å‘Š
                const progressInt = Math.floor(progress / 10) * 10;
                if (progressInt > 0 && progressInt <= 90 && progress % 10 < 2) {
                  const estimatedTotalSeconds = (estimatedTotalRows / parseFloat(speed));
                  const remainingSeconds = Math.max(0, estimatedTotalSeconds - parseFloat(elapsed)).toFixed(0);
                  const remainingMinutes = (parseFloat(remainingSeconds) / 60).toFixed(1);
                  
                  console.log(`\nğŸ“Š [è¿›åº¦æŠ¥å‘Š] ${progressInt}% | å·²å¤„ç†: ${rowCount.toLocaleString()} è¡Œ | é€Ÿåº¦: ${speed} è¡Œ/ç§’`);
                  console.log(`â±ï¸  å·²ç”¨æ—¶: ${elapsed}ç§’ | é¢„è®¡å‰©ä½™: ${remainingMinutes}åˆ†é’Ÿ | æ‰¹æ¬¡: #${saveCount}`);
                  console.log(`ğŸ’¾ å†…å­˜ä½¿ç”¨: ${(process.memoryUsage().heapUsed / 1024 / 1024).toFixed(1)}MB\n`);
                }
                
                // æ¸…ç©ºæ‰¹æ¬¡
                batch = [];
                
                // å¼ºåˆ¶åƒåœ¾å›æ”¶
                if (global.gc) {
                  global.gc();
                }
              }
            }
          } catch (error) {
            console.error(`Error processing row ${rowCount}:`, error);
          }
        },
        complete: () => {
          // å¤„ç†å‰©ä½™çš„æ‰¹æ¬¡
          if (batch.length > 0) {
            // ç›´æ¥æ‰¹é‡æ’å…¥ï¼ˆSQL.jsä¸æ”¯æŒäº‹åŠ¡ï¼‰
            for (const item of batch) {
              dbManager!.run('INSERT INTO csv_data (file_id, row_number, row_data, is_header) VALUES (?, ?, ?, ?)', item);
            }
            saveCount++;
          }
          
          // æœ€ç»ˆä¿å­˜
          dbManager!.save();
          resolve();
        },
        error: (error: any) => {
          reject(error);
        }
      });
    });
    
    parseTime = Date.now() - parseStartTime;
    dbInsertTime = Date.now() - dbInsertStartTime;
    
    console.log(`[PARSE-COMPLETE] CSVæµå¼è§£æå®Œæˆï¼Œè€—æ—¶: ${(parseTime / 1000).toFixed(2)}ç§’`);
    console.log(`[DB-INSERT-COMPLETE] æ•°æ®åº“æ’å…¥å®Œæˆï¼Œè€—æ—¶: ${(dbInsertTime / 1000).toFixed(2)}ç§’`);

    if (rowCount === 0) {
      return res.status(400).json({ message: 'CSV file is empty or contains only headers' });
    }

    // æ›´æ–°æ–‡ä»¶çš„è¡Œæ•°
    dbManager.run('UPDATE csv_files SET row_count = ? WHERE id = ?', [rowCount, fileId]);

    // è®¡ç®—æ€»ä½“æ€§èƒ½ç»Ÿè®¡
    const overallTime = Date.now() - overallStartTime;
    const uploadSpeedMBps = (parseFloat(fileSizeMB) / (overallTime / 1000)).toFixed(2);
    const insertSpeedRowsPerSec = Math.round(rowCount / (dbInsertTime / 1000)).toString();
    
    // ç”Ÿæˆè¯¦ç»†çš„æ€§èƒ½æŠ¥å‘Š
    console.log('\n' + '='.repeat(80));
    console.log('ğŸ“Š æ–‡ä»¶ä¸Šä¼ æ€§èƒ½æŠ¥å‘Š');
    console.log('='.repeat(80));
    console.log(`ğŸ“ æ–‡ä»¶ä¿¡æ¯: ${originalName} (${fileSizeGB}GB, ${rowCount.toLocaleString()} è¡Œ)`);
    console.log(`ğŸ‘¤ ç”¨æˆ·ID: ${userId}`);
    console.log(`â±ï¸  æ€»è€—æ—¶: ${(overallTime / 1000).toFixed(2)} ç§’`);
    console.log('');
    console.log('ğŸ“ˆ å„é˜¶æ®µè€—æ—¶åˆ†æ:');
    console.log(`   â€¢ æ–‡ä»¶ä¸Šä¼ : ${(fileUploadTime / 1000).toFixed(2)} ç§’ (${((fileUploadTime / overallTime) * 100).toFixed(1)}%)`);
    console.log(`   â€¢ CSVè§£æ:  ${(parseTime / 1000).toFixed(2)} ç§’ (${((parseTime / overallTime) * 100).toFixed(1)}%)`);
    console.log(`   â€¢ æ•°æ®åº“æ’å…¥: ${(dbInsertTime / 1000).toFixed(2)} ç§’ (${((dbInsertTime / overallTime) * 100).toFixed(1)}%)`);
    console.log('');
    console.log('âš¡ æ€§èƒ½æŒ‡æ ‡:');
    console.log(`   â€¢ ä¸Šä¼ é€Ÿåº¦: ${uploadSpeedMBps} MB/s`);
    console.log(`   â€¢ æ’å…¥é€Ÿåº¦: ${insertSpeedRowsPerSec} è¡Œ/ç§’`);
    console.log(`   â€¢ æ‰¹æ¬¡ä¿å­˜: ${saveCount} æ¬¡ (æ¯ ${batchSize} è¡Œä¿å­˜ä¸€æ¬¡)`);
    console.log('='.repeat(80));

    res.status(201).json({
      message: 'File uploaded successfully',
      fileId: fileId,
      filename: originalName,
      rowCount: rowCount,
      performance: {
        totalTime: `${(overallTime / 1000).toFixed(2)}s`,
        fileUploadTime: `${(fileUploadTime / 1000).toFixed(2)}s`,
        parseTime: `${(parseTime / 1000).toFixed(2)}s`,
        dbInsertTime: `${(dbInsertTime / 1000).toFixed(2)}s`,
        uploadSpeed: `${uploadSpeedMBps} MB/s`,
        insertSpeed: `${insertSpeedRowsPerSec} è¡Œ/ç§’`,
        saveCount: saveCount
      }
    });
  } catch (error) {
    console.error('Upload error:', error);
    res.status(500).json({ message: 'Failed to upload file' });
  } finally {
    if (dbManager) {
      dbManager.close();
    }
  }
});

// è·å–ç”¨æˆ·çš„CSVæ–‡ä»¶åˆ—è¡¨ - æ”¯æŒæ··åˆæ•°æ®åº“æŸ¥è¯¢
router.get('/list', authenticateToken, async (req: AuthRequest, res: Response) => {
  let sqliteDb: DatabaseManager | null = null;
  let fileDb: DatabaseManager | null = null;
  try {
    const userId = req.userId!;
    const allFiles: any[] = [];
    
    // 1. æŸ¥è¯¢SQLiteæ•°æ®åº“ä¸­çš„å°æ–‡ä»¶
    try {
      sqliteDb = await SmartDatabaseSelector.createOptimizedDatabase(0);
      const sqliteFiles = sqliteDb.all(
        'SELECT id, original_name, upload_date, row_count FROM csv_files WHERE user_id = ? ORDER BY upload_date DESC',
        [userId]
      );
      allFiles.push(...sqliteFiles);
    } catch (error) {
      console.warn('SQLite query failed:', error);
    }
    
    // 2. æŸ¥è¯¢æ–‡ä»¶æ•°æ®åº“ä¸­çš„å¤§æ–‡ä»¶
    try {
      fileDb = await SmartDatabaseSelector.createOptimizedDatabase(1000); // ä½¿ç”¨å¤§æ–‡ä»¶æ•°æ®åº“
      const fileDbFiles = fileDb.all(
        'SELECT id, original_name, upload_date, row_count FROM csv_files WHERE user_id = ? ORDER BY upload_date DESC',
        [userId]
      );
      allFiles.push(...fileDbFiles);
    } catch (error) {
      console.warn('File database query failed:', error);
    }
    
    // 3. å»é‡å¹¶æ’åºï¼ˆåŸºäºIDå»é‡ï¼ŒæŒ‰ä¸Šä¼ æ—¥æœŸæ’åºï¼‰
    const uniqueFiles = allFiles.filter((file, index, self) => 
      index === self.findIndex((f) => f.id === file.id)
    );
    
    uniqueFiles.sort((a, b) => new Date(b.upload_date).getTime() - new Date(a.upload_date).getTime());

    res.json({ files: uniqueFiles });
  } catch (error) {
    console.error('List error:', error);
    res.status(500).json({ message: 'Failed to retrieve file list' });
  } finally {
    if (sqliteDb) {
      sqliteDb.close();
    }
    if (fileDb) {
      fileDb.close();
    }
  }
});

// è·å–CSVæ–‡ä»¶çš„åˆ†é¡µæ•°æ® - æ”¯æŒå¤§æ•°æ®é‡å’Œæ··åˆæ•°æ®åº“
router.get('/:id', authenticateToken, async (req: AuthRequest, res: Response) => {
  let sqliteDb: DatabaseManager | null = null;
  let fileDb: DatabaseManager | null = null;
  let targetDb: DatabaseManager | null = null;
  let file: any = null;
  
  try {
    const userId = req.userId!;
    const fileId = parseInt(req.params.id);
    
    // è·å–åˆ†é¡µå‚æ•°
    const page = parseInt(req.query.page as string) || 1;
    const pageSize = parseInt(req.query.pageSize as string) || 100;
    const offset = (page - 1) * pageSize;

    // 1. å…ˆåœ¨SQLiteä¸­æŸ¥æ‰¾æ–‡ä»¶
    try {
      sqliteDb = await SmartDatabaseSelector.createOptimizedDatabase(0);
      file = sqliteDb.get('SELECT * FROM csv_files WHERE id = ? AND user_id = ?', [fileId, userId]) as any;
      if (file) {
        targetDb = sqliteDb;
      }
    } catch (error) {
      console.warn('SQLite file query failed:', error);
    }
    
    // 2. å¦‚æœSQLiteä¸­æ²¡æœ‰ï¼Œåœ¨æ–‡ä»¶æ•°æ®åº“ä¸­æŸ¥æ‰¾
    if (!file) {
      try {
        fileDb = await SmartDatabaseSelector.createOptimizedDatabase(1000);
        file = fileDb.get('SELECT * FROM csv_files WHERE id = ? AND user_id = ?', [fileId, userId]) as any;
        if (file) {
          targetDb = fileDb;
        }
      } catch (error) {
        console.warn('File database query failed:', error);
      }
    }

    if (!file || !targetDb) {
      return res.status(404).json({ message: 'File not found' });
    }

    // è·å–è¡¨å¤´ï¼ˆå…¼å®¹æ—§æ ¼å¼å’Œæ–°æ ¼å¼ï¼‰
    let headers: string[] = [];
    console.log(`[DEBUG] å°è¯•è·å–æ–‡ä»¶ ${fileId} çš„è¡¨å¤´...`);
    
    // å¯¹äºå¤§æ–‡ä»¶ï¼Œä½¿ç”¨æµå¼è¯»å–è¡¨å¤´
    if (targetDb.getDbType() === 'filedb') {
      try {
        const dataFile = path.join(__dirname, '../../data', `csv_data_${fileId}.jsonl`);
        if (fs.existsSync(dataFile)) {
          headers = await new Promise<string[]>((resolve, reject) => {
            const readStream = fs.createReadStream(dataFile, { encoding: 'utf-8' });
            let buffer = '';
            let found = false;
            
            readStream.on('data', (chunk: string | Buffer) => {
              const chunkStr = chunk instanceof Buffer ? chunk.toString('utf-8') : chunk;
              buffer += chunkStr;
              const lines = buffer.split('\n');
              buffer = lines.pop() || ''; // ä¿ç•™æœ€åä¸€ä¸ªä¸å®Œæ•´çš„è¡Œ
              
              for (const line of lines) {
                if (line.trim()) {
                  try {
                    const row = JSON.parse(line);
                    if (row.file_id === fileId && row.is_header === 1) {
                      const headerData = JSON.parse(row.row_data);
                      console.log(`[DEBUG] æµå¼è¯»å–è¡¨å¤´æˆåŠŸ:`, headerData);
                      found = true;
                      readStream.destroy();
                      resolve(headerData);
                      return;
                    }
                  } catch (e) {
                    // å¿½ç•¥è§£æé”™è¯¯
                  }
                }
              }
            });
            
            readStream.on('end', () => {
              if (!found && buffer.trim()) {
                try {
                  const row = JSON.parse(buffer);
                  if (row.file_id === fileId && row.is_header === 1) {
                    const headerData = JSON.parse(row.row_data);
                    console.log(`[DEBUG] åœ¨æœ€åbufferä¸­æ‰¾åˆ°è¡¨å¤´:`, headerData);
                    resolve(headerData);
                    return;
                  }
                } catch (e) {
                  // å¿½ç•¥è§£æé”™è¯¯
                }
              }
              resolve([]);
            });
            
            readStream.on('error', (error) => {
              console.warn('[DEBUG] æµå¼è¯»å–è¡¨å¤´å¤±è´¥:', error);
              resolve([]);
            });
          });
        }
      } catch (error) {
        console.warn('[DEBUG] æµå¼è¯»å–è¡¨å¤´å¤±è´¥:', error);
      }
    }
    
    // å¦‚æœç›´æ¥è¯»å–å¤±è´¥ï¼Œå°è¯•æ•°æ®åº“æŸ¥è¯¢
    if (headers.length === 0) {
      // å‡å°‘ç­‰å¾…æ—¶é—´ï¼Œæé«˜å“åº”é€Ÿåº¦
      await new Promise(resolve => setTimeout(resolve, 100));
      
      try {
        const headerRow = await targetDb.getAsync('SELECT row_data FROM csv_data WHERE file_id = ? AND is_header = 1', [fileId]) as any;
        console.log(`[DEBUG] è¡¨å¤´æŸ¥è¯¢ç»“æœ:`, headerRow ? 'æ‰¾åˆ°è¡¨å¤´' : 'æœªæ‰¾åˆ°è¡¨å¤´');
        if (headerRow) {
          try {
            headers = JSON.parse(headerRow.row_data);
            console.log(`[DEBUG] è§£æè¡¨å¤´æˆåŠŸ:`, headers);
          } catch (parseError) {
            console.warn('[DEBUG] JSONè§£æå¤±è´¥ï¼Œå°è¯•CSVæ ¼å¼:', parseError);
            // å…¼å®¹æ—§æ ¼å¼ï¼ˆCSVå­—ç¬¦ä¸²ï¼‰
            headers = headerRow.row_data.split(',').map((h: string) => h.trim());
            console.log(`[DEBUG] CSVæ ¼å¼è¡¨å¤´:`, headers);
          }
        }
      } catch (error) {
        console.warn('[DEBUG] getAsyncæ–¹æ³•å¤±è´¥:', error);
        // å¦‚æœgetAsyncå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨åŒæ­¥æ–¹æ³•
        try {
          const headerRow = targetDb.get('SELECT row_data FROM csv_data WHERE file_id = ? AND is_header = 1', [fileId]) as any;
          console.log(`[DEBUG] åŒæ­¥æ–¹æ³•è¡¨å¤´æŸ¥è¯¢ç»“æœ:`, headerRow ? 'æ‰¾åˆ°è¡¨å¤´' : 'æœªæ‰¾åˆ°è¡¨å¤´');
          if (headerRow) {
            try {
              headers = JSON.parse(headerRow.row_data);
              console.log(`[DEBUG] åŒæ­¥æ–¹æ³•è§£æè¡¨å¤´æˆåŠŸ:`, headers);
            } catch (parseError) {
              console.warn('[DEBUG] åŒæ­¥æ–¹æ³•JSONè§£æå¤±è´¥ï¼Œå°è¯•CSVæ ¼å¼:', parseError);
              // å…¼å®¹æ—§æ ¼å¼ï¼ˆCSVå­—ç¬¦ä¸²ï¼‰
              headers = headerRow.row_data.split(',').map((h: string) => h.trim());
              console.log(`[DEBUG] åŒæ­¥æ–¹æ³•CSVæ ¼å¼è¡¨å¤´:`, headers);
            }
          }
        } catch (syncError) {
          console.error('[DEBUG] åŒæ­¥æ–¹æ³•ä¹Ÿå¤±è´¥:', syncError);
        }
      }
    }

    // è·å–æ€»è®°å½•æ•°
    const countResult = await targetDb.getAsync('SELECT COUNT(*) as total FROM csv_data WHERE file_id = ? AND is_header = 0', [fileId]) as any;
    const totalRows = countResult ? countResult.total : 0;

    // è·å–åˆ†é¡µæ•°æ® - å¯¹äºå¤§æ–‡ä»¶ä½¿ç”¨æµå¼è¯»å–
    let rows: any[] = [];
    if (targetDb.getDbType() === 'filedb') {
      try {
        const dataFile = path.join(__dirname, '../../data', `csv_data_${fileId}.jsonl`);
        if (fs.existsSync(dataFile)) {
          rows = await new Promise<any[]>((resolve, reject) => {
            const readStream = fs.createReadStream(dataFile, { encoding: 'utf-8' });
            let buffer = '';
            let dataRows: any[] = [];
            let currentRow = 0;
            let targetStartRow = offset + 1; // è·³è¿‡è¡¨å¤´è¡Œ
            let targetEndRow = targetStartRow + pageSize;
            let found = false;
            
            readStream.on('data', (chunk: string | Buffer) => {
              const chunkStr = chunk instanceof Buffer ? chunk.toString('utf-8') : chunk;
              buffer += chunkStr;
              const lines = buffer.split('\n');
              buffer = lines.pop() || ''; // ä¿ç•™æœ€åä¸€ä¸ªä¸å®Œæ•´çš„è¡Œ
              
              for (const line of lines) {
                if (line.trim()) {
                  try {
                    const row = JSON.parse(line);
                    if (row.file_id === fileId && row.is_header === 0) {
                      currentRow++;
                      
                      if (currentRow >= targetStartRow && currentRow < targetEndRow) {
                        dataRows.push(row);
                      }
                      
                      if (currentRow >= targetEndRow) {
                        found = true;
                        readStream.destroy();
                        resolve(dataRows);
                        return;
                      }
                    }
                  } catch (e) {
                    // å¿½ç•¥è§£æé”™è¯¯
                  }
                }
              }
            });
            
            readStream.on('end', () => {
              if (!found && buffer.trim()) {
                try {
                  const row = JSON.parse(buffer);
                  if (row.file_id === fileId && row.is_header === 0) {
                    currentRow++;
                    if (currentRow >= targetStartRow && currentRow < targetEndRow) {
                      dataRows.push(row);
                    }
                  }
                } catch (e) {
                  // å¿½ç•¥è§£æé”™è¯¯
                }
              }
              resolve(dataRows);
            });
            
            readStream.on('error', (error) => {
              console.warn('[DEBUG] æµå¼è¯»å–æ•°æ®å¤±è´¥:', error);
              resolve([]);
            });
          });
        }
      } catch (error) {
        console.warn('[DEBUG] æµå¼è¯»å–æ•°æ®å¤±è´¥:', error);
      }
    } else {
      // å°æ–‡ä»¶ä½¿ç”¨æ•°æ®åº“æŸ¥è¯¢
      rows = targetDb.all(
        'SELECT row_number, row_data FROM csv_data WHERE file_id = ? AND is_header = 0 ORDER BY row_number LIMIT ? OFFSET ?',
        [fileId, pageSize, offset]
      ) as any[];
    }

    // è§£ææ•°æ®ï¼ˆå…¼å®¹æ—§æ ¼å¼å’Œæ–°æ ¼å¼ï¼‰
    const data = rows.map((row: any) => {
      let values: string[];
      try {
        values = JSON.parse(row.row_data);
      } catch {
        // å…¼å®¹æ—§æ ¼å¼ï¼ˆCSVå­—ç¬¦ä¸²ï¼‰
        values = row.row_data.split(',').map((v: string) => v.trim());
      }
      const obj: any = { _rowNumber: row.row_number };
      headers.forEach((header: string, index: number) => {
        obj[header] = values[index] || '';
      });
      return obj;
    });

    res.json({
      file: {
        id: file.id,
        name: file.original_name,
        uploadDate: file.upload_date,
        totalRows: file.row_count || totalRows
      },
      headers,
      data,
      pagination: {
        currentPage: page,
        pageSize: pageSize,
        totalRows: totalRows,
        totalPages: Math.ceil(totalRows / pageSize)
      }
    });
  } catch (error) {
    console.error('Get file error:', error);
    res.status(500).json({ message: 'Failed to retrieve file data' });
  } finally {
    if (sqliteDb) {
      sqliteDb.close();
    }
    if (fileDb) {
      fileDb.close();
    }
  }
});

// è·å–å•è¡Œæ•°æ®è¯¦æƒ… - æ”¯æŒæ··åˆæ•°æ®åº“æŸ¥è¯¢
router.get('/:id/row/:rowNumber', authenticateToken, async (req: AuthRequest, res: Response) => {
  let sqliteDb: DatabaseManager | null = null;
  let fileDb: DatabaseManager | null = null;
  let targetDb: DatabaseManager | null = null;
  let file: any = null;
  
  try {
    const userId = req.userId!;
    const fileId = parseInt(req.params.id);
    const rowNumber = parseInt(req.params.rowNumber);

    // 1. å…ˆåœ¨SQLiteä¸­æŸ¥æ‰¾æ–‡ä»¶
    try {
      sqliteDb = await SmartDatabaseSelector.createOptimizedDatabase(0);
      file = sqliteDb.get('SELECT * FROM csv_files WHERE id = ? AND user_id = ?', [fileId, userId]) as any;
      if (file) {
        targetDb = sqliteDb;
      }
    } catch (error) {
      console.warn('SQLite file query failed:', error);
    }
    
    // 2. å¦‚æœSQLiteä¸­æ²¡æœ‰ï¼Œåœ¨æ–‡ä»¶æ•°æ®åº“ä¸­æŸ¥æ‰¾
    if (!file) {
      try {
        fileDb = await SmartDatabaseSelector.createOptimizedDatabase(1000);
        file = fileDb.get('SELECT * FROM csv_files WHERE id = ? AND user_id = ?', [fileId, userId]) as any;
        if (file) {
          targetDb = fileDb;
        }
      } catch (error) {
        console.warn('File database query failed:', error);
      }
    }

    if (!file || !targetDb) {
      return res.status(404).json({ message: 'File not found' });
    }

    // è·å–è¡¨å¤´ï¼ˆå…¼å®¹æ—§æ ¼å¼å’Œæ–°æ ¼å¼ï¼‰
    let headers: string[] = [];
    
    // å¯¹äºå¤§æ–‡ä»¶ï¼Œä½¿ç”¨æµå¼è¯»å–è¡¨å¤´
    if (targetDb.getDbType() === 'filedb') {
      try {
        const dataFile = path.join(__dirname, '../../data', `csv_data_${fileId}.jsonl`);
        if (fs.existsSync(dataFile)) {
          headers = await new Promise<string[]>((resolve, reject) => {
            const readStream = fs.createReadStream(dataFile, { encoding: 'utf-8' });
            let buffer = '';
            let found = false;
            
            readStream.on('data', (chunk: string | Buffer) => {
              const chunkStr = chunk instanceof Buffer ? chunk.toString('utf-8') : chunk;
              buffer += chunkStr;
              const lines = buffer.split('\n');
              buffer = lines.pop() || ''; // ä¿ç•™æœ€åä¸€ä¸ªä¸å®Œæ•´çš„è¡Œ
              
              for (const line of lines) {
                if (line.trim()) {
                  try {
                    const row = JSON.parse(line);
                    if (row.file_id === fileId && row.is_header === 1) {
                      const headerData = JSON.parse(row.row_data);
                      console.log(`[DEBUG] å•è¡ŒæŸ¥è¯¢-æµå¼è¯»å–è¡¨å¤´æˆåŠŸ:`, headerData);
                      found = true;
                      readStream.destroy();
                      resolve(headerData);
                      return;
                    }
                  } catch (e) {
                    // å¿½ç•¥è§£æé”™è¯¯
                  }
                }
              }
            });
            
            readStream.on('end', () => {
              if (!found && buffer.trim()) {
                try {
                  const row = JSON.parse(buffer);
                  if (row.file_id === fileId && row.is_header === 1) {
                    const headerData = JSON.parse(row.row_data);
                    console.log(`[DEBUG] å•è¡ŒæŸ¥è¯¢-åœ¨æœ€åbufferä¸­æ‰¾åˆ°è¡¨å¤´:`, headerData);
                    resolve(headerData);
                    return;
                  }
                } catch (e) {
                  // å¿½ç•¥è§£æé”™è¯¯
                }
              }
              resolve([]);
            });
            
            readStream.on('error', (error) => {
              console.warn('[DEBUG] å•è¡ŒæŸ¥è¯¢-æµå¼è¯»å–è¡¨å¤´å¤±è´¥:', error);
              resolve([]);
            });
          });
        }
      } catch (error) {
        console.warn('[DEBUG] å•è¡ŒæŸ¥è¯¢-æµå¼è¯»å–è¡¨å¤´å¤±è´¥:', error);
      }
    }
    
    // å¦‚æœæµå¼è¯»å–å¤±è´¥ï¼Œå°è¯•æ•°æ®åº“æŸ¥è¯¢
    if (headers.length === 0) {
      try {
        const headerRow = await targetDb.getAsync('SELECT row_data FROM csv_data WHERE file_id = ? AND is_header = 1', [fileId]) as any;
        console.log(`[DEBUG] å•è¡ŒæŸ¥è¯¢-è¡¨å¤´æŸ¥è¯¢ç»“æœ:`, headerRow ? 'æ‰¾åˆ°è¡¨å¤´' : 'æœªæ‰¾åˆ°è¡¨å¤´');
        if (headerRow) {
          try {
            headers = JSON.parse(headerRow.row_data);
            console.log(`[DEBUG] å•è¡ŒæŸ¥è¯¢-è§£æè¡¨å¤´æˆåŠŸ:`, headers);
          } catch (parseError) {
            console.warn('[DEBUG] å•è¡ŒæŸ¥è¯¢-JSONè§£æå¤±è´¥ï¼Œå°è¯•CSVæ ¼å¼:', parseError);
            // å…¼å®¹æ—§æ ¼å¼ï¼ˆCSVå­—ç¬¦ä¸²ï¼‰
            headers = headerRow.row_data.split(',').map((h: string) => h.trim());
            console.log(`[DEBUG] å•è¡ŒæŸ¥è¯¢-CSVæ ¼å¼è¡¨å¤´:`, headers);
          }
        }
      } catch (error) {
        console.warn('[DEBUG] å•è¡ŒæŸ¥è¯¢-getAsyncæ–¹æ³•å¤±è´¥:', error);
        // å¦‚æœgetAsyncå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨åŒæ­¥æ–¹æ³•
        try {
          const headerRow = targetDb.get('SELECT row_data FROM csv_data WHERE file_id = ? AND is_header = 1', [fileId]) as any;
          console.log(`[DEBUG] å•è¡ŒæŸ¥è¯¢-åŒæ­¥æ–¹æ³•è¡¨å¤´æŸ¥è¯¢ç»“æœ:`, headerRow ? 'æ‰¾åˆ°è¡¨å¤´' : 'æœªæ‰¾åˆ°è¡¨å¤´');
          if (headerRow) {
            try {
              headers = JSON.parse(headerRow.row_data);
              console.log(`[DEBUG] å•è¡ŒæŸ¥è¯¢-åŒæ­¥æ–¹æ³•è§£æè¡¨å¤´æˆåŠŸ:`, headers);
            } catch (parseError) {
              console.warn('[DEBUG] å•è¡ŒæŸ¥è¯¢-åŒæ­¥æ–¹æ³•JSONè§£æå¤±è´¥ï¼Œå°è¯•CSVæ ¼å¼:', parseError);
              // å…¼å®¹æ—§æ ¼å¼ï¼ˆCSVå­—ç¬¦ä¸²ï¼‰
              headers = headerRow.row_data.split(',').map((h: string) => h.trim());
              console.log(`[DEBUG] å•è¡ŒæŸ¥è¯¢-åŒæ­¥æ–¹æ³•CSVæ ¼å¼è¡¨å¤´:`, headers);
            }
          }
        } catch (syncError) {
          console.error('[DEBUG] å•è¡ŒæŸ¥è¯¢-åŒæ­¥æ–¹æ³•ä¹Ÿå¤±è´¥:', syncError);
        }
      }
    }

    // è·å–æŒ‡å®šè¡Œæ•°æ® - å¯¹äºå¤§æ–‡ä»¶ä½¿ç”¨æµå¼è¯»å–
    let row: any = null;
    
    if (targetDb.getDbType() === 'filedb') {
      try {
        const dataFile = path.join(__dirname, '../../data', `csv_data_${fileId}.jsonl`);
        if (fs.existsSync(dataFile)) {
          row = await new Promise<any>((resolve, reject) => {
            const readStream = fs.createReadStream(dataFile, { encoding: 'utf-8' });
            let buffer = '';
            let currentRow = 0;
            let found = false;
            
            readStream.on('data', (chunk: string | Buffer) => {
              const chunkStr = chunk instanceof Buffer ? chunk.toString('utf-8') : chunk;
              buffer += chunkStr;
              const lines = buffer.split('\n');
              buffer = lines.pop() || ''; // ä¿ç•™æœ€åä¸€ä¸ªä¸å®Œæ•´çš„è¡Œ
              
              for (const line of lines) {
                if (line.trim()) {
                  try {
                    const rowData = JSON.parse(line);
                    if (rowData.file_id === fileId && rowData.is_header === 0) {
                      currentRow++;
                      
                      if (currentRow === rowNumber) {
                        found = true;
                        readStream.destroy();
                        resolve(rowData);
                        return;
                      }
                    }
                  } catch (e) {
                    // å¿½ç•¥è§£æé”™è¯¯
                  }
                }
              }
            });
            
            readStream.on('end', () => {
              if (!found && buffer.trim()) {
                try {
                  const rowData = JSON.parse(buffer);
                  if (rowData.file_id === fileId && rowData.is_header === 0) {
                    currentRow++;
                    if (currentRow === rowNumber) {
                      resolve(rowData);
                      return;
                    }
                  }
                } catch (e) {
                  // å¿½ç•¥è§£æé”™è¯¯
                }
              }
              resolve(null);
            });
            
            readStream.on('error', (error) => {
              console.warn('[DEBUG] æµå¼è¯»å–å•è¡Œæ•°æ®å¤±è´¥:', error);
              resolve(null);
            });
          });
        }
      } catch (error) {
        console.warn('[DEBUG] æµå¼è¯»å–å•è¡Œæ•°æ®å¤±è´¥:', error);
      }
    } else {
      // å°æ–‡ä»¶ä½¿ç”¨æ•°æ®åº“æŸ¥è¯¢
      row = await targetDb.getAsync('SELECT row_data FROM csv_data WHERE file_id = ? AND row_number = ?', [fileId, rowNumber]) as any;
    }
    
    if (!row) {
      return res.status(404).json({ message: 'Row not found' });
    }

    // è§£ææ•°æ®ï¼ˆå…¼å®¹æ—§æ ¼å¼å’Œæ–°æ ¼å¼ï¼‰
    let values: string[];
    try {
      values = JSON.parse(row.row_data);
    } catch {
      // å…¼å®¹æ—§æ ¼å¼ï¼ˆCSVå­—ç¬¦ä¸²ï¼‰
      values = row.row_data.split(',').map((v: string) => v.trim());
    }
    
    const data: any = {};
    headers.forEach((header: string, index: number) => {
      data[header] = values[index] || '';
    });

    res.json({
      headers,
      data,
      rowNumber
    });
  } catch (error) {
    console.error('Get row error:', error);
    res.status(500).json({ message: 'Failed to retrieve row data' });
  } finally {
    if (sqliteDb) {
      sqliteDb.close();
    }
    if (fileDb) {
      fileDb.close();
    }
  }
});

// æ‰¹é‡åˆ é™¤CSVæ–‡ä»¶ - æ”¯æŒæ··åˆæ•°æ®åº“
router.post('/batch-delete', authenticateToken, async (req: AuthRequest, res: Response) => {
  let sqliteDb: DatabaseManager | null = null;
  let fileDb: DatabaseManager | null = null;
  try {
    const userId = req.userId!;
    const { fileIds } = req.body;

    if (!Array.isArray(fileIds) || fileIds.length === 0) {
      return res.status(400).json({ message: 'No files selected' });
    }

    sqliteDb = await SmartDatabaseSelector.createOptimizedDatabase(0);
    fileDb = await SmartDatabaseSelector.createOptimizedDatabase(1000);
    let deletedCount = 0;

    for (const fileId of fileIds) {
      let file = null;
      let targetDb = null;

      // å…ˆåœ¨SQLiteä¸­æŸ¥æ‰¾æ–‡ä»¶
      try {
        file = sqliteDb.get('SELECT filename FROM csv_files WHERE id = ? AND user_id = ?', [fileId, userId]) as any;
        if (file) {
          targetDb = sqliteDb;
        }
      } catch (error) {
        console.warn('SQLite file query failed:', error);
      }
      
      // å¦‚æœSQLiteä¸­æ²¡æœ‰ï¼Œåœ¨æ–‡ä»¶æ•°æ®åº“ä¸­æŸ¥æ‰¾
      if (!file) {
        try {
          file = fileDb.get('SELECT filename FROM csv_files WHERE id = ? AND user_id = ?', [fileId, userId]) as any;
          if (file) {
            targetDb = fileDb;
          }
        } catch (error) {
          console.warn('File database query failed:', error);
        }
      }

      if (file && targetDb) {
        // åˆ é™¤ç‰©ç†æ–‡ä»¶
        const filePath = path.join(uploadDir, file.filename);
        if (fs.existsSync(filePath)) {
          fs.unlinkSync(filePath);
        }

        // åˆ é™¤æ•°æ®æ–‡ä»¶ï¼ˆå¯¹äºå¤§æ–‡ä»¶ï¼‰
        if (targetDb.getDbType() === 'filedb') {
          try {
            const dataFile = path.join(__dirname, '../../data', `csv_data_${fileId}.jsonl`);
            if (fs.existsSync(dataFile)) {
              fs.unlinkSync(dataFile);
              console.log(`[DELETE] åˆ é™¤æ•°æ®æ–‡ä»¶: csv_data_${fileId}.jsonl`);
            }
          } catch (error) {
            console.warn('Failed to delete data file:', error);
          }
        }

        // åˆ é™¤CSVæ•°æ®
        targetDb.run('DELETE FROM csv_data WHERE file_id = ?', [fileId]);
        
        // åˆ é™¤æ–‡ä»¶è®°å½•
        targetDb.run('DELETE FROM csv_files WHERE id = ?', [fileId]);
        
        deletedCount++;
        console.log(`[DELETE] æˆåŠŸåˆ é™¤æ–‡ä»¶ ID: ${fileId}, åç§°: ${file.filename}`);
      } else {
        console.warn(`[DELETE] æœªæ‰¾åˆ°æ–‡ä»¶ ID: ${fileId}, ç”¨æˆ·ID: ${userId}`);
      }
    }

    res.json({ message: `Successfully deleted ${deletedCount} file(s)`, deletedCount });
  } catch (error) {
    console.error('Batch delete error:', error);
    res.status(500).json({ message: 'Failed to delete files' });
  } finally {
    if (sqliteDb) {
      sqliteDb.close();
    }
    if (fileDb) {
      fileDb.close();
    }
  }
});

// åˆ é™¤CSVæ–‡ä»¶ - æ”¯æŒæ··åˆæ•°æ®åº“
router.delete('/:id', authenticateToken, async (req: AuthRequest, res: Response) => {
  let sqliteDb: DatabaseManager | null = null;
  let fileDb: DatabaseManager | null = null;
  try {
    const userId = req.userId!;
    const fileId = parseInt(req.params.id);

    sqliteDb = await SmartDatabaseSelector.createOptimizedDatabase(0);
    fileDb = await SmartDatabaseSelector.createOptimizedDatabase(1000);
    
    let file = null;
    let targetDb = null;

    // ä½¿ç”¨ä¸åˆ—è¡¨APIå®Œå…¨ç›¸åŒçš„æŸ¥è¯¢é€»è¾‘
    const allFiles: any[] = [];
    
    // 1. æŸ¥è¯¢SQLiteæ•°æ®åº“ä¸­çš„å°æ–‡ä»¶
    try {
      const sqliteFiles = sqliteDb.all(
        'SELECT id, filename, user_id FROM csv_files WHERE user_id = ?',
        [userId]
      );
      allFiles.push(...sqliteFiles);
      console.log(`[DELETE] SQLiteæ‰¾åˆ° ${sqliteFiles.length} ä¸ªæ–‡ä»¶`);
    } catch (error) {
      console.warn('SQLite query failed:', error);
    }
    
    // 2. æŸ¥è¯¢æ–‡ä»¶æ•°æ®åº“ä¸­çš„å¤§æ–‡ä»¶
    try {
      const fileDbFiles = fileDb.all(
        'SELECT id, filename, user_id FROM csv_files WHERE user_id = ?',
        [userId]
      );
      allFiles.push(...fileDbFiles);
      console.log(`[DELETE] æ–‡ä»¶æ•°æ®åº“æ‰¾åˆ° ${fileDbFiles.length} ä¸ªæ–‡ä»¶`);
    } catch (error) {
      console.warn('File database query failed:', error);
    }
    
    // 3. å»é‡å¹¶æŸ¥æ‰¾ç›®æ ‡æ–‡ä»¶
    const uniqueFiles = allFiles.filter((file, index, self) => 
      index === self.findIndex((f) => f.id === file.id)
    );
    
    console.log(`[DELETE] æ€»å…±æ‰¾åˆ° ${uniqueFiles.length} ä¸ªå”¯ä¸€æ–‡ä»¶ï¼ŒæŸ¥æ‰¾ID: ${fileId}`);
    
    const targetFile = uniqueFiles.find(f => f.id === fileId);
    if (targetFile) {
      file = targetFile;
      // ç¡®å®šä½¿ç”¨å“ªä¸ªæ•°æ®åº“
      try {
        const sqliteFile = sqliteDb.get('SELECT filename FROM csv_files WHERE id = ?', [fileId]) as any;
        if (sqliteFile) {
          targetDb = sqliteDb;
          console.log(`[DELETE] ä½¿ç”¨SQLiteæ•°æ®åº“`);
        }
      } catch (error) {
        // å¿½ç•¥é”™è¯¯
      }
      
      if (!targetDb) {
        targetDb = fileDb;
        console.log(`[DELETE] ä½¿ç”¨æ–‡ä»¶æ•°æ®åº“`);
      }
      console.log(`[DELETE] æ‰¾åˆ°æ–‡ä»¶ ID: ${fileId}, åç§°: ${file.filename}`);
    } else {
      console.log(`[DELETE] åœ¨æ‰€æœ‰æ–‡ä»¶ä¸­æœªæ‰¾åˆ°ID: ${fileId}`);
      console.log(`[DELETE] å¯ç”¨æ–‡ä»¶ID: ${uniqueFiles.map(f => f.id).join(', ')}`);
    }

    if (!file || !targetDb) {
      console.warn(`[DELETE] æ–‡ä»¶æœªæ‰¾åˆ° - ID: ${fileId}, ç”¨æˆ·ID: ${userId}`);
      return res.status(404).json({ message: 'File not found' });
    }

    // åˆ é™¤ç‰©ç†æ–‡ä»¶
    const filePath = path.join(uploadDir, file.filename);
    if (fs.existsSync(filePath)) {
      fs.unlinkSync(filePath);
      console.log(`[DELETE] åˆ é™¤ç‰©ç†æ–‡ä»¶: ${file.filename}`);
    }

    // åˆ é™¤æ•°æ®æ–‡ä»¶ï¼ˆå¯¹äºå¤§æ–‡ä»¶ï¼‰
    if (targetDb.getDbType() === 'filedb') {
      try {
        const dataFile = path.join(__dirname, '../../data', `csv_data_${fileId}.jsonl`);
        if (fs.existsSync(dataFile)) {
          fs.unlinkSync(dataFile);
          console.log(`[DELETE] åˆ é™¤æ•°æ®æ–‡ä»¶: csv_data_${fileId}.jsonl`);
        }
      } catch (error) {
        console.warn('Failed to delete data file:', error);
      }
    }

    // åˆ é™¤CSVæ•°æ®
    targetDb.run('DELETE FROM csv_data WHERE file_id = ?', [fileId]);
    
    // åˆ é™¤æ–‡ä»¶è®°å½•
    targetDb.run('DELETE FROM csv_files WHERE id = ?', [fileId]);

    console.log(`[DELETE] æˆåŠŸåˆ é™¤æ–‡ä»¶ ID: ${fileId}, åç§°: ${file.filename}`);
    res.json({ message: 'File deleted successfully' });
  } catch (error) {
    console.error('Delete error:', error);
    res.status(500).json({ message: 'Failed to delete file' });
  } finally {
    if (sqliteDb) {
      sqliteDb.close();
    }
    if (fileDb) {
      fileDb.close();
    }
  }
});

export default router;
